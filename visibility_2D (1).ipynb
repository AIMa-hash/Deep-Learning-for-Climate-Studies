{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0147s vs `on_train_batch_end` time: 0.0232s). Check your callbacks.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "#mae_list1 = []\n",
    "#mape_list1 = []\n",
    "#for i in range(20):\n",
    "#    print(i)\n",
    "airports = ['VABB', 'VOTV', 'VOBL', 'VECC', 'VIDP']\n",
    "\n",
    "def get_visibility(code):\n",
    "    arr = np.load(\"visibility_arr.npy\")\n",
    "    idx = airports.index(code)\n",
    "    return arr[:, idx].astype(np.float32)\n",
    "\n",
    "def get_era_full(param, level):\n",
    "    arr = np.load(\"18To20{}{}_uint8.npy\".format(param, level))\n",
    "    return (arr/256)#.astype(np.float32)\n",
    "\n",
    "# Import data\n",
    "params = [\"z\", \"z\", \"z\"]\n",
    "levels = [500, 700, 1000]\n",
    "\n",
    "in1_var = get_era_full(params[0], levels[0])\n",
    "in2_var = get_era_full(params[1], levels[1])\n",
    "in3_var = get_era_full(params[2], levels[2])\n",
    "\n",
    "# data for a given airport\n",
    "X = np.concatenate((np.expand_dims(in1_var, axis=3), np.expand_dims(in2_var, axis=3), np.expand_dims(in3_var, axis=3)), axis=3)\n",
    "Y = get_visibility('VABB').reshape(-1, 1)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, Y_train, Y_rem = train_test_split(X,Y, train_size=0.7)\n",
    "\n",
    "# Now since we want the valid and test size to be equal. \n",
    "X_valid, X_test, Y_valid, Y_test = train_test_split(X_rem,Y_rem, test_size=0.5)\n",
    "\n",
    "#to clear space for gpu, if occupied by any process\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# model\n",
    "\n",
    "initializer = tf.keras.initializers.HeUniform()\n",
    "inputs = keras.Input(shape=(157, 157, 3))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", kernel_initializer = initializer)(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", kernel_initializer = initializer)(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", kernel_initializer = initializer)(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", kernel_initializer = initializer)(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=512, kernel_size=3, activation=\"relu\", kernel_initializer = initializer)(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "top_dropout_rate = 0.4\n",
    "x = layers.Dropout(top_dropout_rate)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs, name=\"Basic2dCNN\")\n",
    "\n",
    "# compiling the model\n",
    "opt =tf.keras.optimizers.RMSprop(learning_rate=0.002)\n",
    "model.compile(loss = 'mse', optimizer = opt, metrics = [tf.keras.losses.MeanAbsoluteError()])\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(filepath = f\"vVABB_2D.keras\",\n",
    "                                            save_best_only = True, monitor = \"val_loss\")]\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size = 64, epochs = 100, validation_data = (X_valid, Y_valid), verbose = 0, callbacks = callbacks)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "f1 = plt.figure();\n",
    "mae = history.history[\"mean_absolute_error\"]\n",
    "loss = history.history[\"loss\"]\n",
    "mape = history.history[\"mean_absolute_percentage_error\"]\n",
    "val_mae = history.history[\"val_mean_absolute_error\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "val_mape = history.history[\"val_mean_absolute_percentage_error\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, \"bo\", label = \"Training loss(MSE)\")\n",
    "plt.plot(epochs, val_loss, \"b\", label = \"Validation loss(MSE)\")\n",
    "plt.title(\"Training and validation loss(MSE)\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "f2 = plt.figure();\n",
    "plt.plot(epochs, mae, \"bo\", label = \"Training accuracy(MAE)\")\n",
    "plt.plot(epochs, val_mae, \"b\", label = \"Validation accuracy(MAE)\")\n",
    "plt.title(\"Training and validation accuracy(MAE)\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test MAE: {test_mae:.3f}\")\n",
    "#mae_list1.append(test_mae)\n",
    "#mape_list1.append(test_mape)\n",
    "f1.savefig(f\"vVABBl_2D.jpg\", bbox_inches='tight', dpi=600);\n",
    "f2.savefig(f\"vVABBm_2D.jpg\", bbox_inches='tight', dpi=600);\n",
    "#f3.savefig(f\"vVABB{i}mape_2D.jpg\", bbox_inches='tight', dpi=600);\n",
    "    \n",
    "#print(mae_list1)\n",
    "#print(mape_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mae_list1 = [0.4781510531902313, 0.4756133258342743, 0.4818015694618225, 0.47948676347732544, 0.47266677021980286, 0.4710808992385864, 0.46902909874916077, 0.47727319598197937, 0.4791882038116455, 0.489938884973526, 0.4724079370498657, 0.46932166814804077, 0.4712788462638855, 0.4628233313560486, 0.4710977375507355, 0.4838845729827881, 0.48105090856552124, 0.46335792541503906, 0.4775252044200897, 0.48078182339668274]\n",
    "a = np.array(mae_list1)\n",
    "np.mean(a), np.std(a), a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "mae_list2 = []\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    airports = ['VABB', 'VOTV', 'VOBL', 'VECC', 'VIDP']\n",
    "\n",
    "    def get_visibility(code):\n",
    "        arr = np.load(\"visibility_arr.npy\")\n",
    "        idx = airports.index(code)\n",
    "        return arr[:, idx].astype(np.float32)\n",
    "\n",
    "    def get_era_full(param, level):\n",
    "        arr = np.load(\"18To20{}{}_uint8.npy\".format(param, level))\n",
    "        return arr.astype(np.float32)\n",
    "\n",
    "    # Import data\n",
    "    params = [\"z\", \"z\", \"z\"]\n",
    "    levels = [500, 700, 1000]\n",
    "\n",
    "    in1_var = get_era_full(params[0], levels[0])\n",
    "    in2_var = get_era_full(params[1], levels[1])\n",
    "    in3_var = get_era_full(params[2], levels[2])\n",
    "\n",
    "    # data for a given airport\n",
    "    X = np.concatenate((np.expand_dims(in1_var, axis=3), np.expand_dims(in2_var, axis=3), np.expand_dims(in3_var, axis=3)), axis=3)\n",
    "    Y = get_visibility('VOTV').reshape(-1, 1)\n",
    "\n",
    "    import sklearn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # In the first step we will split the data in training and remaining dataset\n",
    "    X_train, X_rem, Y_train, Y_rem = train_test_split(X,Y, train_size=0.7)\n",
    "\n",
    "    # Now since we want the valid and test size to be equal. \n",
    "    X_valid, X_test, Y_valid, Y_test = train_test_split(X_rem,Y_rem, test_size=0.5)\n",
    "\n",
    "    #to clear space for gpu, if occupied by any process\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.compat.v1 import ConfigProto\n",
    "    from tensorflow.compat.v1 import InteractiveSession\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    conv_base = tf.keras.applications.vgg16.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(157, 157, 3))\n",
    "\n",
    "    # preprocess_input\n",
    "\n",
    "    train_features = tf.keras.applications.vgg16.preprocess_input(X_train)\n",
    "    val_features = tf.keras.applications.vgg16.preprocess_input(X_valid)\n",
    "    test_features = tf.keras.applications.vgg16.preprocess_input(X_test)\n",
    "\n",
    "    train_features = conv_base.predict(X_train)\n",
    "    val_features = conv_base.predict(X_valid)\n",
    "    test_features = conv_base.predict(X_test)\n",
    "\n",
    "    train_labels = Y_train\n",
    "    val_labels = Y_valid\n",
    "    test_labels = Y_test\n",
    "\n",
    "    # model building\n",
    "    inputs = keras.Input(shape = (4,4,512))\n",
    "    x = layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    top_dropout_rate = 0.4\n",
    "    x = layers.Dropout(top_dropout_rate)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"vgg16\")\n",
    "\n",
    "    # compiling the model\n",
    "    opt =tf.keras.optimizers.RMSprop(learning_rate=0.002)\n",
    "    model.compile(loss = 'mse', optimizer = opt, metrics = [tf.keras.losses.MeanAbsoluteError()])\n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(filepath = f\"vVOTV {i}_vgg16.keras\",\n",
    "                                                save_best_only = True, monitor = \"val_loss\")]\n",
    "\n",
    "    history = model.fit(train_features, train_labels, batch_size = 128, epochs = 100, validation_data = (val_features, val_labels), verbose = 0, callbacks = callbacks)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    f1 = plt.figure();\n",
    "    mae = history.history[\"mean_absolute_error\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_mae = history.history[\"val_mean_absolute_error\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, \"bo\", label = \"Training loss(MSE)\");\n",
    "    plt.plot(epochs, val_loss, \"b\", label = \"Validation loss(MSE)\");\n",
    "    plt.title(\"Training and validation loss(MSE)\");\n",
    "    plt.legend();\n",
    "\n",
    "    f2 = plt.figure();\n",
    "    plt.plot(epochs, mae, \"bo\", label = \"Training accuracy(MAE)\");\n",
    "    plt.plot(epochs, val_mae, \"b\", label = \"Validation accuracy(MAE)\");\n",
    "    plt.title(\"Training and validation accuracy(MAE)\");\n",
    "    plt.legend();\n",
    "    plt.show();\n",
    "\n",
    "    test_loss, test_mae = model.evaluate(test_features, test_labels)\n",
    "    print(f\"Test MAE: {test_mae:.3f}\")\n",
    "    mae_list2.append(test_mae)\n",
    "    f1.savefig(f\"vVOTV{i}_vgg16.jpg\", bbox_inches='tight', dpi=600);\n",
    "    f2.savefig(f\"vVOTV{i}_vgg16.jpg\", bbox_inches='tight', dpi=600);\n",
    "    \n",
    "print(mae_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(mae_list2)\n",
    "np.mean(b), np.std(b), b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "mae_list3 = []\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    airports = ['VABB', 'VOTV', 'VOBL', 'VECC', 'VIDP']\n",
    "\n",
    "    def get_visibility(code):\n",
    "        arr = np.load(\"visibility_arr.npy\")\n",
    "        idx = airports.index(code)\n",
    "        return arr[:, idx].astype(np.float32)\n",
    "\n",
    "    def get_era_full(param, level):\n",
    "        arr = np.load(\"18To20{}{}_uint8.npy\".format(param, level))\n",
    "        return arr.astype(np.float32)\n",
    "\n",
    "    # Import data\n",
    "    params = [\"z\", \"z\", \"z\"]\n",
    "    levels = [500, 700, 1000]\n",
    "\n",
    "    in1_var = get_era_full(params[0], levels[0])\n",
    "    in2_var = get_era_full(params[1], levels[1])\n",
    "    in3_var = get_era_full(params[2], levels[2])\n",
    "\n",
    "    # data for a given airport\n",
    "    X = np.concatenate((np.expand_dims(in1_var, axis=3), np.expand_dims(in2_var, axis=3), np.expand_dims(in3_var, axis=3)), axis=3)\n",
    "    Y = get_visibility('VOBL').reshape(-1, 1)\n",
    "\n",
    "    import sklearn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # In the first step we will split the data in training and remaining dataset\n",
    "    X_train, X_rem, Y_train, Y_rem = train_test_split(X,Y, train_size=0.7)\n",
    "\n",
    "    # Now since we want the valid and test size to be equal. \n",
    "    X_valid, X_test, Y_valid, Y_test = train_test_split(X_rem,Y_rem, test_size=0.5)\n",
    "\n",
    "    #to clear space for gpu, if occupied by any process\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.compat.v1 import ConfigProto\n",
    "    from tensorflow.compat.v1 import InteractiveSession\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    conv_base = tf.keras.applications.vgg16.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(157, 157, 3))\n",
    "\n",
    "    # preprocess_input\n",
    "\n",
    "    train_features = tf.keras.applications.vgg16.preprocess_input(X_train)\n",
    "    val_features = tf.keras.applications.vgg16.preprocess_input(X_valid)\n",
    "    test_features = tf.keras.applications.vgg16.preprocess_input(X_test)\n",
    "\n",
    "    train_features = conv_base.predict(X_train)\n",
    "    val_features = conv_base.predict(X_valid)\n",
    "    test_features = conv_base.predict(X_test)\n",
    "\n",
    "    train_labels = Y_train\n",
    "    val_labels = Y_valid\n",
    "    test_labels = Y_test\n",
    "\n",
    "    # model building\n",
    "    inputs = keras.Input(shape = (4,4,512))\n",
    "    x = layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    top_dropout_rate = 0.4\n",
    "    x = layers.Dropout(top_dropout_rate)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"vgg16\")\n",
    "\n",
    "    # compiling the model\n",
    "    opt =tf.keras.optimizers.RMSprop(learning_rate=0.002)\n",
    "    model.compile(loss = 'mse', optimizer = opt, metrics = [tf.keras.losses.MeanAbsoluteError()])\n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(filepath = f\"vVABB{i}_vgg16.keras\",\n",
    "                                                save_best_only = True, monitor = \"val_loss\")]\n",
    "\n",
    "    history = model.fit(train_features, train_labels, batch_size = 128, epochs = 100, validation_data = (val_features, val_labels), verbose = 0, callbacks = callbacks)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    f1 = plt.figure();\n",
    "    mae = history.history[\"mean_absolute_error\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_mae = history.history[\"val_mean_absolute_error\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, \"bo\", label = \"Training loss(MSE)\");\n",
    "    plt.plot(epochs, val_loss, \"b\", label = \"Validation loss(MSE)\");\n",
    "    plt.title(\"Training and validation loss(MSE)\");\n",
    "    plt.legend();\n",
    "\n",
    "    f2 = plt.figure();\n",
    "    plt.plot(epochs, mae, \"bo\", label = \"Training accuracy(MAE)\");\n",
    "    plt.plot(epochs, val_mae, \"b\", label = \"Validation accuracy(MAE)\");\n",
    "    plt.title(\"Training and validation accuracy(MAE)\");\n",
    "    plt.legend();\n",
    "    plt.show();\n",
    "\n",
    "    test_loss, test_mae = model.evaluate(test_features, test_labels)\n",
    "    print(f\"Test MAE: {test_mae:.3f}\")\n",
    "    mae_list3.append(test_mae)\n",
    "    f1.savefig(f\"vVOBL{i}_vgg16.jpg\", bbox_inches='tight', dpi=600);\n",
    "    f2.savefig(f\"vVOBL{i}_vgg16.jpg\", bbox_inches='tight', dpi=600);\n",
    "    \n",
    "print(mae_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array(mae_list3)\n",
    "np.mean(c), np.std(c), c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "mae_list4 = []\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    airports = ['VABB', 'VOTV', 'VOBL', 'VECC', 'VIDP']\n",
    "\n",
    "    def get_visibility(code):\n",
    "        arr = np.load(\"visibility_arr.npy\")\n",
    "        idx = airports.index(code)\n",
    "        return arr[:, idx].astype(np.float32)\n",
    "\n",
    "    def get_era_full(param, level):\n",
    "        arr = np.load(\"18To20{}{}_uint8.npy\".format(param, level))\n",
    "        return arr.astype(np.float32)\n",
    "\n",
    "    # Import data\n",
    "    params = [\"z\", \"z\", \"z\"]\n",
    "    levels = [500, 700, 1000]\n",
    "\n",
    "    in1_var = get_era_full(params[0], levels[0])\n",
    "    in2_var = get_era_full(params[1], levels[1])\n",
    "    in3_var = get_era_full(params[2], levels[2])\n",
    "\n",
    "    # data for a given airport\n",
    "    X = np.concatenate((np.expand_dims(in1_var, axis=3), np.expand_dims(in2_var, axis=3), np.expand_dims(in3_var, axis=3)), axis=3)\n",
    "    Y = get_visibility('VECC').reshape(-1, 1)\n",
    "\n",
    "    import sklearn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # In the first step we will split the data in training and remaining dataset\n",
    "    X_train, X_rem, Y_train, Y_rem = train_test_split(X,Y, train_size=0.7)\n",
    "\n",
    "    # Now since we want the valid and test size to be equal. \n",
    "    X_valid, X_test, Y_valid, Y_test = train_test_split(X_rem,Y_rem, test_size=0.5)\n",
    "\n",
    "    #to clear space for gpu, if occupied by any process\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.compat.v1 import ConfigProto\n",
    "    from tensorflow.compat.v1 import InteractiveSession\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    conv_base = tf.keras.applications.vgg16.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(157, 157, 3))\n",
    "\n",
    "    # preprocess_input\n",
    "\n",
    "    train_features = tf.keras.applications.vgg16.preprocess_input(X_train)\n",
    "    val_features = tf.keras.applications.vgg16.preprocess_input(X_valid)\n",
    "    test_features = tf.keras.applications.vgg16.preprocess_input(X_test)\n",
    "\n",
    "    train_features = conv_base.predict(X_train)\n",
    "    val_features = conv_base.predict(X_valid)\n",
    "    test_features = conv_base.predict(X_test)\n",
    "\n",
    "    train_labels = Y_train\n",
    "    val_labels = Y_valid\n",
    "    test_labels = Y_test\n",
    "\n",
    "    # model building\n",
    "    inputs = keras.Input(shape = (4,4,512))\n",
    "    x = layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    top_dropout_rate = 0.4\n",
    "    x = layers.Dropout(top_dropout_rate)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"vgg16\")\n",
    "\n",
    "    # compiling the model\n",
    "    opt =tf.keras.optimizers.RMSprop(learning_rate=0.002)\n",
    "    model.compile(loss = 'mse', optimizer = opt, metrics = [tf.keras.losses.MeanAbsoluteError()])\n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(filepath = f\"vVECC{i}_vgg16.keras\",\n",
    "                                                save_best_only = True, monitor = \"val_loss\")]\n",
    "\n",
    "    history = model.fit(train_features, train_labels, batch_size = 128, epochs = 100, validation_data = (val_features, val_labels), verbose = 0, callbacks = callbacks)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    f1 = plt.figure();\n",
    "    mae = history.history[\"mean_absolute_error\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_mae = history.history[\"val_mean_absolute_error\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, \"bo\", label = \"Training loss(MSE)\");\n",
    "    plt.plot(epochs, val_loss, \"b\", label = \"Validation loss(MSE)\");\n",
    "    plt.title(\"Training and validation loss(MSE)\");\n",
    "    plt.legend();\n",
    "\n",
    "    f2 = plt.figure()\n",
    "    plt.plot(epochs, mae, \"bo\", label = \"Training accuracy(MAE)\");\n",
    "    plt.plot(epochs, val_mae, \"b\", label = \"Validation accuracy(MAE)\");\n",
    "    plt.title(\"Training and validation accuracy(MAE)\");\n",
    "    plt.legend();\n",
    "    plt.show();\n",
    "\n",
    "    test_loss, test_mae = model.evaluate(test_features, test_labels)\n",
    "    print(f\"Test MAE: {test_mae:.3f}\")\n",
    "    mae_list4.append(test_mae)\n",
    "    f1.savefig(f\"vVECC{i}_vgg16.jpg\", bbox_inches='tight', dpi=600);\n",
    "    f2.savefig(f\"vVECC{i}_vgg16.jpg\", bbox_inches='tight', dpi=600);\n",
    "    \n",
    "print(mae_list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array(mae_list4)\n",
    "np.mean(d), np.std(d), d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "mae_list5 = []\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    airports = ['VABB', 'VOTV', 'VOBL', 'VECC', 'VIDP']\n",
    "\n",
    "    def get_visibility(code):\n",
    "        arr = np.load(\"visibility_arr.npy\")\n",
    "        idx = airports.index(code)\n",
    "        return arr[:, idx].astype(np.float32)\n",
    "\n",
    "    def get_era_full(param, level):\n",
    "        arr = np.load(\"18To20{}{}_uint8.npy\".format(param, level))\n",
    "        return arr.astype(np.float32)\n",
    "\n",
    "    # Import data\n",
    "    params = [\"z\", \"z\", \"z\"]\n",
    "    levels = [500, 700, 1000]\n",
    "\n",
    "    in1_var = get_era_full(params[0], levels[0])\n",
    "    in2_var = get_era_full(params[1], levels[1])\n",
    "    in3_var = get_era_full(params[2], levels[2])\n",
    "\n",
    "    # data for a given airport\n",
    "    X = np.concatenate((np.expand_dims(in1_var, axis=3), np.expand_dims(in2_var, axis=3), np.expand_dims(in3_var, axis=3)), axis=3)\n",
    "    Y = get_visibility('VIDP').reshape(-1, 1)\n",
    "\n",
    "    import sklearn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # In the first step we will split the data in training and remaining dataset\n",
    "    X_train, X_rem, Y_train, Y_rem = train_test_split(X,Y, train_size=0.7)\n",
    "\n",
    "    # Now since we want the valid and test size to be equal. \n",
    "    X_valid, X_test, Y_valid, Y_test = train_test_split(X_rem,Y_rem, test_size=0.5)\n",
    "\n",
    "    #to clear space for gpu, if occupied by any process\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.compat.v1 import ConfigProto\n",
    "    from tensorflow.compat.v1 import InteractiveSession\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    conv_base = tf.keras.applications.vgg16.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(157, 157, 3))\n",
    "\n",
    "    # preprocess_input\n",
    "\n",
    "    train_features = tf.keras.applications.vgg16.preprocess_input(X_train)\n",
    "    val_features = tf.keras.applications.vgg16.preprocess_input(X_valid)\n",
    "    test_features = tf.keras.applications.vgg16.preprocess_input(X_test)\n",
    "\n",
    "    train_features = conv_base.predict(X_train)\n",
    "    val_features = conv_base.predict(X_valid)\n",
    "    test_features = conv_base.predict(X_test)\n",
    "\n",
    "    train_labels = Y_train\n",
    "    val_labels = Y_valid\n",
    "    test_labels = Y_test\n",
    "\n",
    "    # model building\n",
    "    inputs = keras.Input(shape = (4,4,512))\n",
    "    x = layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    top_dropout_rate = 0.4\n",
    "    x = layers.Dropout(top_dropout_rate)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"vgg16\")\n",
    "\n",
    "    # compiling the model\n",
    "    opt =tf.keras.optimizers.RMSprop(learning_rate=0.002)\n",
    "    model.compile(loss = 'mse', optimizer = opt, metrics = [tf.keras.losses.MeanAbsoluteError()])\n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(filepath = f\"vVIDP{i}_vgg16.keras\",\n",
    "                                                save_best_only = True, monitor = \"val_loss\")]\n",
    "\n",
    "    history = model.fit(train_features, train_labels, batch_size = 128, epochs = 100, validation_data = (val_features, val_labels), verbose = 0, callbacks = callbacks)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    f1 = plt.figure();\n",
    "    mae = history.history[\"mean_absolute_error\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_mae = history.history[\"val_mean_absolute_error\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, \"bo\", label = \"Training loss(MSE)\");\n",
    "    plt.plot(epochs, val_loss, \"b\", label = \"Validation loss(MSE)\");\n",
    "    plt.title(\"Training and validation loss(MSE)\");\n",
    "    plt.legend();\n",
    "\n",
    "    f2 = plt.figure();\n",
    "    plt.plot(epochs, mae, \"bo\", label = \"Training accuracy(MAE)\");\n",
    "    plt.plot(epochs, val_mae, \"b\", label = \"Validation accuracy(MAE)\");\n",
    "    plt.title(\"Training and validation accuracy(MAE)\");\n",
    "    plt.legend();\n",
    "    plt.show();\n",
    "\n",
    "    test_loss, test_mae = model.evaluate(test_features, test_labels)\n",
    "    print(f\"Test MAE: {test_mae:.3f}\")\n",
    "    mae_list5.append(test_mae)\n",
    "    f1.savefig(f\"vVIDP{i}_vgg16.jpg\", bbox_inches='tight', dpi=600);\n",
    "    f2.savefig(f\"vVIDP{i}_vgg16.jpg\", bbox_inches='tight', dpi=600);\n",
    "    \n",
    "print(mae_list5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.array(mae_list5)\n",
    "np.mean(e), np.std(e), e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = pd.Series(mae_list5)\n",
    "x.plot.hist(bins=50, figsize=[10, 5])\n",
    "plt.xlabel(\"visibility\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
